library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[1:90]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
data.new[1:90]
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[80:85]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
output
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[80:82]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
output
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[82:83]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
output
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[82:84]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
output
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[82:85]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
data.new
data.new[82:85]
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[82:85]
data.new
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
output<-data.new %>%  get_wiki
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[82:85]
droplevels(data.new)
output<-data.new %>%  get_wiki
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[86:90]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[86:88]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[88:89]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
output
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
data.new<-data.new[89:90]
droplevels(data.new)
# loop over each species
output<-data.new %>%  get_wiki
output
data.new
# Planet Earth 2 Analysis
# UK run 6 November to 11 December 2016
# This encompasses week 44 to week 50
# US run 18 February to 25 March 2017
# This encompasses week 7 to week 12
# leaf-tailed gecko, grass-cutter ant, Shovel-snouted lizard and web-footed gecko don't have a wiki page
# clean everything first
rm(list=ls())
library(dplyr)
library(pageviews)
library(data.table)
# load in the data which is a vector of species names
setwd("C:\\Users\\akane\\Desktop\\Science\\Manuscripts\\Documentary analysis\\Documentary-analysis")
data<-read.csv("mentionedNames.csv", header = TRUE, sep = ",")
head(data)
length(data$name)
# test data for function
# data.new<-head(data,1)
# remove the duplicated values
data.new<-data[!duplicated(data), ]
length(data.new)
class(data.new)
#data.test<-head(data.new,1)
# modify the function from pageviews package to collect data for each species - UK air dates
get_wiki <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2016-01-01'), end = as.Date("2016-12-31")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
# US air dates
get_wikiUSA <- function(x){article_pageviews(project = "en.wikipedia", article = x
, start = as.Date('2017-01-01'), end = as.Date("2017-04-20")
, user_type = "user", platform = c("desktop", "mobile-web"))
}
output<-data.new %>%  get_wiki
output
tail(output)
